{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-29T19:52:18.804605Z",
     "start_time": "2025-07-29T19:52:18.746949Z"
    }
   },
   "source": [
    "## 1. DataSet import\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prepare_datasets import *\n",
    "from Helper_functions import *\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "X, y, feature_names, categorical_features, continuous_features, actionable_features = get_and_preprocess_cc()\n",
    "\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "X_pos = X[y == 1]\n",
    "X_neg = X[y == 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:52:18.845019Z",
     "start_time": "2025-07-29T19:52:18.829032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Model import NeuralNetwork\n",
    "\n",
    "model0= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model1= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model2= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model3= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model4= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model5= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model6= NeuralNetwork(X.shape[1], 200, 2)"
   ],
   "id": "d04cca57fe3200c3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:52:18.908355Z",
     "start_time": "2025-07-29T19:52:18.878805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [model0,model1, model2, model3, model4, model5, model6]\n",
    "lambdas = [0,0.05,0.1,0.15,0.2,0.25,0.3]\n",
    "\n",
    "model_path = f\"models/communities_model_0.pth\"\n",
    "model0.load_state_dict(torch.load(model_path))\n",
    "model0.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load saved weights\n",
    "for lambda_model, lamda in zip(models[1:], lambdas[1:]):\n",
    "    model_path = f\"models/communities_model_lambda_{lamda:.2f}.pth\"\n",
    "    lambda_model.load_state_dict(torch.load(model_path))\n",
    "    lambda_model.eval()  # Set to evaluation mode\n"
   ],
   "id": "d4fba8209ec24c18",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:52:18.955961Z",
     "start_time": "2025-07-29T19:52:18.940939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "class WrappedModelForAlibi:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()  # Important for consistent behavior\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "            logits = self.model(x_tensor)\n",
    "\n",
    "            if logits.ndim == 1:\n",
    "                logits = logits.unsqueeze(0)  # Ensure shape is (1, num_classes)\n",
    "\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            return probs.numpy()\n"
   ],
   "id": "a57c34d19bac927b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:59:49.378068Z",
     "start_time": "2025-07-29T19:59:00.159900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from alibi.explainers import CEM\n",
    "X_np = X.numpy()\n",
    "\n",
    "# Wrap your model\n",
    "predict_fn = WrappedModelForAlibi(model0).predict\n",
    "\n",
    "# Feature ranges from training data\n",
    "feature_min = X_np.min(axis=0)\n",
    "feature_max = X_np.max(axis=0)\n",
    "feature_range = (feature_min, feature_max)\n",
    "\n",
    "cem = CEM(\n",
    "    predict_fn,\n",
    "    mode='PN',\n",
    "    shape=(1, X_np.shape[1]),\n",
    "    max_iterations=1000,\n",
    "    feature_range = feature_range\n",
    ")\n",
    "# Fit on a sample of training data (preferably more than 1)\n",
    "cem.fit(X_np)\n",
    "\n",
    "# Explain a sample (batch size 1)\n",
    "explanation = cem.explain(X_np[1:2])\n",
    "\n",
    "print(explanation)\n"
   ],
   "id": "c8b1f1a897f1fc32",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No PN found!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation(meta={\n",
      "  'name': 'CEM',\n",
      "  'type': ['blackbox', 'tensorflow', 'keras'],\n",
      "  'explanations': ['local'],\n",
      "  'params': {\n",
      "              'mode': 'PN',\n",
      "              'shape': (1, 100),\n",
      "              'kappa': 0.0,\n",
      "              'beta': 0.1,\n",
      "              'feature_range': (array([1.0005e+04, 1.6000e+00, 0.0000e+00, 2.6800e+00, 3.0000e-02,\n",
      "       1.2000e-01, 4.5800e+00, 9.3800e+00, 4.6400e+00, 1.6600e+00,\n",
      "       0.0000e+00, 0.0000e+00, 1.1576e+04, 3.1680e+01, 0.0000e+00,\n",
      "       7.9100e+00, 4.8100e+00, 5.0000e-01, 3.4600e+00, 1.3785e+04,\n",
      "       5.2370e+03, 5.4720e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "       0.0000e+00, 7.8000e+01, 6.4000e-01, 2.0000e-01, 2.0900e+00,\n",
      "       1.6300e+00, 1.3200e+00, 2.4820e+01, 2.0500e+00, 8.6900e+00,\n",
      "       1.3700e+00, 6.4800e+00, 2.1300e+00, 1.2060e+01, 3.3500e+00,\n",
      "       2.8300e+00, 2.2900e+00, 3.2240e+01, 2.6110e+01, 2.7430e+01,\n",
      "       3.0640e+01, 2.4420e+01, 4.1950e+01, 0.0000e+00, 0.0000e+00,\n",
      "       2.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1500e+00,\n",
      "       0.0000e+00, 9.6000e-01, 4.4000e-01, 1.5800e+00, 1.6100e+00,\n",
      "       1.5800e+00, 1.3930e+01, 5.0000e-02, 3.0600e+00, 1.0000e+00,\n",
      "       3.6000e+01, 3.7470e+01, 1.6860e+01, 0.0000e+00, 3.1200e+00,\n",
      "       1.9390e+03, 0.0000e+00, 0.0000e+00, 1.5700e+04, 2.6600e+04,\n",
      "       3.6700e+04, 0.0000e+00, 9.9000e+01, 1.2000e+02, 1.8200e+02,\n",
      "       0.0000e+00, 1.9200e+02, 1.4900e+01, 1.4100e+01, 1.0100e+01,\n",
      "       0.0000e+00, 0.0000e+00, 1.8000e-01, 6.7500e+00, 1.1830e+01,\n",
      "       2.7950e+01, 3.2830e+01, 9.0000e-01, 1.0000e+01, 0.0000e+00],\n",
      "      dtype=float32), array([7.322564e+06, 5.280000e+00, 9.667000e+01, 9.963000e+01,\n",
      "       5.746000e+01, 9.529000e+01, 5.440000e+01, 7.051000e+01,\n",
      "       6.362000e+01, 5.277000e+01, 7.322564e+06, 1.000000e+02,\n",
      "       1.236250e+05, 9.662000e+01, 6.530000e+00, 8.904000e+01,\n",
      "       7.639000e+01, 2.692000e+01, 4.551000e+01, 1.313150e+05,\n",
      "       6.330200e+04, 6.885000e+04, 2.121200e+05, 4.800000e+05,\n",
      "       1.061650e+05, 5.464800e+04, 1.384994e+06, 4.882000e+01,\n",
      "       4.989000e+01, 7.366000e+01, 7.363000e+01, 2.383000e+01,\n",
      "       8.467000e+01, 5.003000e+01, 6.267000e+01, 4.427000e+01,\n",
      "       6.497000e+01, 1.909000e+01, 7.632000e+01, 2.346000e+01,\n",
      "       1.911000e+01, 4.640000e+00, 9.360000e+01, 9.258000e+01,\n",
      "       1.000000e+02, 9.734000e+01, 8.797000e+01, 8.937000e+01,\n",
      "       5.275570e+05, 2.419000e+01, 2.082931e+06, 6.429000e+01,\n",
      "       7.616000e+01, 8.081000e+01, 8.800000e+01, 1.371000e+01,\n",
      "       1.993000e+01, 2.534000e+01, 3.263000e+01, 9.898000e+01,\n",
      "       3.833000e+01, 3.487000e+01, 3.087000e+01, 4.520000e+00,\n",
      "       4.480000e+00, 4.730000e+00, 9.659000e+01, 5.949000e+01,\n",
      "       9.534000e+01, 4.000000e+00, 1.727680e+05, 9.900000e+01,\n",
      "       9.636000e+01, 3.989000e+01, 8.213000e+01, 1.987000e+03,\n",
      "       2.363000e+01, 5.330000e+00, 5.000010e+05, 5.000010e+05,\n",
      "       5.000010e+05, 3.310000e+05, 1.001000e+03, 1.001000e+03,\n",
      "       1.001000e+03, 8.030000e+02, 1.001000e+03, 3.510000e+01,\n",
      "       3.270000e+01, 2.340000e+01, 2.338300e+04, 1.044700e+04,\n",
      "       6.040000e+01, 9.314000e+01, 7.856000e+01, 9.659000e+01,\n",
      "       9.990000e+01, 3.569800e+03, 4.422990e+04, 5.433000e+01],\n",
      "      dtype=float32)),\n",
      "              'gamma': 0.0,\n",
      "              'learning_rate_init': 0.01,\n",
      "              'max_iterations': 1000,\n",
      "              'c_init': 10.0,\n",
      "              'c_steps': 10,\n",
      "              'eps': (0.001, 0.001),\n",
      "              'clip': (-100.0, 100.0),\n",
      "              'update_num_grad': 1,\n",
      "              'no_info_val': None,\n",
      "              'write_dir': None,\n",
      "              'is_model': False,\n",
      "              'is_ae': False,\n",
      "              'no_info_type': 'median'}\n",
      "            ,\n",
      "  'version': '0.9.6'}\n",
      ", data={\n",
      "  'PN': None,\n",
      "  'PP': None,\n",
      "  'PN_pred': None,\n",
      "  'PP_pred': None,\n",
      "  'grads_graph': None,\n",
      "  'grads_num': None,\n",
      "  'X': array([[2.3123e+04, 2.8200e+00, 8.0000e-01, 9.5570e+01, 3.4400e+00,\n",
      "        8.5000e-01, 1.1010e+01, 2.1300e+01, 1.0480e+01, 1.7180e+01,\n",
      "        2.3123e+04, 1.0000e+02, 4.7917e+04, 7.8990e+01, 1.1100e+00,\n",
      "        6.4110e+01, 3.5500e+01, 2.7500e+00, 2.2850e+01, 5.5323e+04,\n",
      "        2.0148e+04, 2.0191e+04, 1.8137e+04, 0.0000e+00, 2.0074e+04,\n",
      "        1.2222e+04, 8.8500e+02, 3.9800e+00, 5.6100e+00, 1.3720e+01,\n",
      "        2.9890e+01, 2.4300e+00, 6.1960e+01, 1.2260e+01, 2.9280e+01,\n",
      "        6.3900e+00, 3.7640e+01, 4.2300e+00, 2.7990e+01, 6.4500e+00,\n",
      "        5.4200e+00, 3.1100e+00, 8.6910e+01, 8.5330e+01, 9.6820e+01,\n",
      "        8.6460e+01, 5.1140e+01, 6.2430e+01, 4.3000e+01, 2.4000e-01,\n",
      "        1.9200e+03, 5.2100e+00, 8.6500e+00, 1.3330e+01, 2.2500e+01,\n",
      "        4.3000e-01, 7.2000e-01, 1.1100e+00, 1.8700e+00, 8.7790e+01,\n",
      "        1.8100e+00, 4.2500e+00, 3.3400e+00, 2.7000e+00, 2.8300e+00,\n",
      "        1.9600e+00, 8.9030e+01, 1.0100e+00, 2.3600e+01, 3.0000e+00,\n",
      "        2.4000e+02, 9.7150e+01, 8.4880e+01, 0.0000e+00, 1.8330e+01,\n",
      "        1.9580e+03, 3.1000e-01, 1.4000e-01, 1.3630e+05, 1.6420e+05,\n",
      "        1.9990e+05, 6.3600e+04, 4.6700e+02, 5.6000e+02, 6.7200e+02,\n",
      "        2.0500e+02, 6.2700e+02, 2.7600e+01, 2.0700e+01, 1.2500e+01,\n",
      "        0.0000e+00, 0.0000e+00, 8.3000e+00, 7.7170e+01, 7.1270e+01,\n",
      "        9.0220e+01, 9.6120e+01, 1.0600e+01, 2.1867e+03, 3.8400e+00]],\n",
      "      dtype=float32),\n",
      "  'X_pred': 1}\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For communities and crime it is impossible to generate counterfactual for all instances because it takes alot of time and not always work for instance the above try shows that even after 1000 iterations it want able to find a PN and it took around 52 seconds. So we dropped the evaluation with communities and crimes using CEM",
   "id": "c16dae0f7c37db5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
