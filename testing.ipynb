{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-06T18:40:27.655108Z",
     "start_time": "2025-07-06T18:40:27.635115Z"
    }
   },
   "source": [
    "## 1. DataSet import\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prepare_datasets import *\n",
    "from Helper_functions import *\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "X, y, feature_names, categorical_features, continuous_features, actionable_features = get_and_prepare_german_dataset()\n",
    "\n",
    "X = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "X_pos = X[y == 1]\n",
    "X_neg = X[y == 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:40:27.717384Z",
     "start_time": "2025-07-06T18:40:27.703567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Model import NeuralNetwork\n",
    "\n",
    "model = NeuralNetwork(X.shape[1], 200, 2)\n",
    "model1= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model2= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model3= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model4= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model5= NeuralNetwork(X.shape[1], 200, 2)\n",
    "model6= NeuralNetwork(X.shape[1], 200, 2)"
   ],
   "id": "d04cca57fe3200c3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:40:27.795581Z",
     "start_time": "2025-07-06T18:40:27.767004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [model,model1, model2, model3, model4, model5, model6]\n",
    "lambdas = [0,0.05,0.1,0.15,0.2,0.25,0.3]\n",
    "\n",
    "model_path = f\"models/Model_0.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load saved weights\n",
    "for lambda_model, lamda in zip(models[1:], lambdas[1:]):\n",
    "    model_path = f\"models/model_lambda_{lamda:.2f}.pth\"\n",
    "    lambda_model.load_state_dict(torch.load(model_path))\n",
    "    lambda_model.eval()  # Set to evaluation mode\n"
   ],
   "id": "d4fba8209ec24c18",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:40:27.872822Z",
     "start_time": "2025-07-06T18:40:27.860522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "class WrappedModelForAlibi:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()  # Important for consistent behavior\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "            logits = self.model(x_tensor)\n",
    "\n",
    "            if logits.ndim == 1:\n",
    "                logits = logits.unsqueeze(0)  # Ensure shape is (1, num_classes)\n",
    "\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            return probs.numpy()\n"
   ],
   "id": "a57c34d19bac927b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:40:32.846573Z",
     "start_time": "2025-07-06T18:40:27.938064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from alibi.explainers import CEM\n",
    "X_np = X.numpy()\n",
    "\n",
    "# Wrap your model\n",
    "predict_fn = WrappedModelForAlibi(model).predict\n",
    "\n",
    "# Feature ranges from training data\n",
    "feature_min = X_np.min(axis=0)\n",
    "feature_max = X_np.max(axis=0)\n",
    "feature_range = (feature_min, feature_max)\n",
    "\n",
    "cem = CEM(\n",
    "    predict_fn,\n",
    "    mode='PN',\n",
    "    shape=(1, X_np.shape[1]),\n",
    "    max_iterations=100,\n",
    "    feature_range = feature_range\n",
    ")\n",
    "# Fit on a sample of training data (preferably more than 1)\n",
    "cem.fit(X_np)\n",
    "\n",
    "# Explain a sample (batch size 1)\n",
    "explanation = cem.explain(X_np[1:2])\n",
    "\n",
    "print(explanation)\n"
   ],
   "id": "c8b1f1a897f1fc32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation(meta={\n",
      "  'name': 'CEM',\n",
      "  'type': ['blackbox', 'tensorflow', 'keras'],\n",
      "  'explanations': ['local'],\n",
      "  'params': {\n",
      "              'mode': 'PN',\n",
      "              'shape': (1, 27),\n",
      "              'kappa': 0.0,\n",
      "              'beta': 0.1,\n",
      "              'feature_range': (array([  0.,   0.,   0.,  19.,   4., 250.,   1.,   1.,   1.,   1.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         0.,   0.,   0.,   0.,   0.], dtype=float32), array([1.0000e+00, 1.0000e+00, 1.0000e+00, 7.5000e+01, 7.2000e+01,\n",
      "       1.8424e+04, 4.0000e+00, 4.0000e+00, 4.0000e+00, 2.0000e+00,\n",
      "       1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "       1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "       1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "       1.0000e+00, 1.0000e+00], dtype=float32)),\n",
      "              'gamma': 0.0,\n",
      "              'learning_rate_init': 0.01,\n",
      "              'max_iterations': 100,\n",
      "              'c_init': 10.0,\n",
      "              'c_steps': 10,\n",
      "              'eps': (0.001, 0.001),\n",
      "              'clip': (-100.0, 100.0),\n",
      "              'update_num_grad': 1,\n",
      "              'no_info_val': None,\n",
      "              'write_dir': None,\n",
      "              'is_model': False,\n",
      "              'is_ae': False,\n",
      "              'no_info_type': 'median'}\n",
      "            ,\n",
      "  'version': '0.9.6'}\n",
      ", data={\n",
      "  'PN': array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2000000e+01,\n",
      "        4.8000000e+01, 5.9510000e+03, 2.0000000e+00, 2.0000000e+00,\n",
      "        1.0000000e+00, 1.2425781e+00, 7.3690844e-01, 1.0000000e+00,\n",
      "        0.0000000e+00, 4.4621745e-01, 2.7172664e-01, 1.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
      "        9.5790541e-01, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
      "        0.0000000e+00, 5.1478839e-01, 9.0195704e-01]], dtype=float32),\n",
      "  'PP': None,\n",
      "  'PN_pred': 1,\n",
      "  'PP_pred': None,\n",
      "  'grads_graph': array([[-0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "        -0.        , -0.        , -0.        , -0.        ,  0.4191184 ,\n",
      "         1.2462882 , -0.        , -0.        ,  0.80197144,  0.48870277,\n",
      "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
      "         1.6346015 , -0.        , -0.        , -0.        , -0.        ,\n",
      "         0.92124104, -0.21647179]], dtype=float32),\n",
      "  'grads_num': array([[ 1.79471620e+01, -2.29788927e+00, -4.61827928e+00,\n",
      "        -3.51855531e+00, -1.36973328e+00,  1.40629698e-02,\n",
      "         8.55872337e+00, -3.24292108e+00,  1.53848901e+00,\n",
      "        -1.54720792e+01, -2.63793208e+01, -1.66505575e+00,\n",
      "         2.90822220e+00, -1.87740647e+01, -1.55142681e+01,\n",
      "         4.60421631e+00,  3.49211665e+01, -2.34289077e+00,\n",
      "         7.45618646e+00,  1.67939984e+01, -3.07557145e+01,\n",
      "        -6.98648393e+00,  2.18060412e+01,  1.82931111e+01,\n",
      "         1.43442292e-01, -2.01606736e+01,  1.11631856e+01]]),\n",
      "  'X': array([[1.000e+00, 0.000e+00, 0.000e+00, 2.200e+01, 4.800e+01, 5.951e+03,\n",
      "        2.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
      "        0.000e+00, 0.000e+00, 1.000e+00]], dtype=float32),\n",
      "  'X_pred': 0}\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:40:32.940263Z",
     "start_time": "2025-07-06T18:40:32.926627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Original instance and counterfactual from Alibi\n",
    "original = torch.tensor(explanation.data['X'][0], dtype=torch.float32)\n",
    "cf = torch.tensor(explanation.data['PN'][0], dtype=torch.float32)\n",
    "\n",
    "# L1 distance\n",
    "distance = torch.norm(original - cf, p=1)\n",
    "\n",
    "print(\"L1 Distance between original and PN:\", distance.item())"
   ],
   "id": "f574ec76380e4297",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Distance between original and PN: 3.26816725730896\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-06T18:40:33.021394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "X_false_negatives, X_true_negatives, _, _  = split_by_classification(model,X_neg)\n",
    "\n",
    "l1_distances = []\n",
    "l2_distances = []\n",
    "\n",
    "# Loop over each instance\n",
    "for i in tqdm(range(len(X_true_negatives)), desc=\"Generating CEM counterfactuals\"):\n",
    "    x = X_true_negatives[i:i+1]  # keep shape (1, n_features)\n",
    "    explanation = cem.explain(x)\n",
    "\n",
    "    # Extract original and PN (pertinent negative) instance\n",
    "    original = explanation.data['X'][0]\n",
    "    pn = explanation.data['PN']\n",
    "\n",
    "    if pn is not None:\n",
    "        cf = pn[0]\n",
    "        l1_distance = torch.norm(original - cf, p=1).item()\n",
    "        l2_distance = torch.norm(original - cf, p=2).item()\n",
    "        l1_distances.append(l1_distance)\n",
    "        l2_distances.append(l2_distance)\n",
    "\n",
    "l1_distances = np.array(l1_distances)\n",
    "l2_distances = np.array(l2_distances)\n",
    "# Print stats\n",
    "print(\"Mean L1 Distance:\", np.mean(l1_distances))\n",
    "print(\"Mean L2 Distance:\", np.mean(l2_distances))"
   ],
   "id": "2f56a9560bc9b35a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CEM counterfactuals:   0%|          | 0/122 [00:00<?, ?it/s]C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_2532\\218918381.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_tensor = torch.tensor(x, dtype=torch.float32)\n",
      "Generating CEM counterfactuals:   2%|▏         | 3/122 [00:13<09:11,  4.63s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:38:15.973621500Z",
     "start_time": "2025-07-06T18:15:05.402856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fist we calculate this subset\n",
    "_, commun_negatives, _, _ = split_by_classification(model, X_neg)\n",
    "\n",
    "for current_model in models:\n",
    "    _, commun_negatives, _, _ = split_by_classification(current_model, commun_negatives)\n",
    "\n",
    "print(len(commun_negatives))"
   ],
   "id": "d68ff9de8be8d00a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T18:38:15.989872800Z",
     "start_time": "2025-07-06T18:19:41.347093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cost_of_recourses_l1 = []\n",
    "cost_of_recourses_l2 = []\n",
    "\n",
    "for (best_model, lamda ) in zip(models,lambdas):\n",
    "    print(f\"Evaluating using CEM with lambda = {lamda}\")\n",
    "    X_np = X.numpy()\n",
    "\n",
    "    predict_fn = WrappedModelForAlibi(best_model).predict\n",
    "    # Feature ranges from training data\n",
    "    feature_min = X_np.min(axis=0)\n",
    "    feature_max = X_np.max(axis=0)\n",
    "    feature_range = (feature_min, feature_max)\n",
    "\n",
    "    cem = CEM(\n",
    "        predict_fn,\n",
    "        mode='PN',\n",
    "        shape=(1, X_np.shape[1]),\n",
    "        max_iterations=100,\n",
    "        feature_range = feature_range\n",
    "    )\n",
    "    # Fit on a sample of training data (preferably more than 1)\n",
    "    cem.fit(X_np)\n",
    "\n",
    "\n",
    "    l1_distances = []\n",
    "    l2_distances = []\n",
    "\n",
    "    # Loop over each instance\n",
    "    for i in tqdm(range(len(commun_negatives)), desc=\"Generating CEM counterfactuals\"):\n",
    "        x = commun_negatives[i:i+1]  # keep shape (1, n_features)\n",
    "        explanation = cem.explain(x)\n",
    "\n",
    "        # Extract original and PN (pertinent negative) instance\n",
    "        original = explanation.data['X'][0]\n",
    "        pn = explanation.data['PN']\n",
    "\n",
    "        if pn is not None:\n",
    "            cf = pn[0]\n",
    "            l1_distance = torch.norm(original - cf, p=1).item()\n",
    "            l2_distance = torch.norm(original - cf, p=2).item()\n",
    "            l1_distances.append(l1_distance)\n",
    "            l2_distances.append(l2_distance)\n",
    "\n",
    "    l1_distances = np.array(l1_distances)\n",
    "    l2_distances = np.array(l2_distances)\n",
    "\n",
    "    # Compute mean L1 distance\n",
    "    cost_of_recourses_l1.append(l1_distances)\n",
    "    cost_of_recourses_l2.append(l1_distances)\n",
    "\n",
    "    print(f\"Mean L1 distance for negatively classified data using DiCE: {np.mean(l1_distances):.2f}\")\n",
    "    print(f\"Mean L2 distance for negatively classified data using DiCE: {np.mean(l2_distances):.2f}\")\n",
    "\n"
   ],
   "id": "a2c167fa84665134",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using CEM with lambda = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CEM counterfactuals:   0%|          | 0/122 [00:00<?, ?it/s]C:\\Users\\hamma\\AppData\\Local\\Temp\\ipykernel_14952\\187860461.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_tensor = torch.tensor(x, dtype=torch.float32)\n",
      "Generating CEM counterfactuals:   2%|▏         | 3/122 [00:23<15:42,  7.92s/it]No PN found!\n",
      "Generating CEM counterfactuals:  15%|█▍        | 18/122 [01:47<09:51,  5.69s/it]No PN found!\n",
      "Generating CEM counterfactuals:  19%|█▉        | 23/122 [02:15<09:15,  5.62s/it]No PN found!\n",
      "Generating CEM counterfactuals:  21%|██▏       | 26/122 [02:32<08:57,  5.59s/it]No PN found!\n",
      "Generating CEM counterfactuals:  27%|██▋       | 33/122 [03:12<08:24,  5.67s/it]No PN found!\n",
      "Generating CEM counterfactuals:  31%|███       | 38/122 [03:40<07:57,  5.68s/it]No PN found!\n",
      "Generating CEM counterfactuals:  48%|████▊     | 59/122 [05:38<05:41,  5.42s/it]No PN found!\n",
      "Generating CEM counterfactuals:  52%|█████▏    | 64/122 [06:01<04:29,  4.65s/it]No PN found!\n",
      "Generating CEM counterfactuals:  56%|█████▌    | 68/122 [06:19<04:08,  4.61s/it]No PN found!\n",
      "Generating CEM counterfactuals:  58%|█████▊    | 71/122 [06:33<03:48,  4.48s/it]No PN found!\n",
      "Generating CEM counterfactuals:  59%|█████▉    | 72/122 [06:37<03:46,  4.54s/it]No PN found!\n",
      "Generating CEM counterfactuals:  74%|███████▍  | 90/122 [07:59<02:26,  4.57s/it]No PN found!\n",
      "Generating CEM counterfactuals:  99%|█████████▉| 121/122 [10:21<00:04,  4.58s/it]No PN found!\n",
      "Generating CEM counterfactuals: 100%|██████████| 122/122 [10:26<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean L1 distance for negatively classified data using DiCE: 2.83\n",
      "Mean L2 distance for negatively classified data using DiCE: 1.34\n",
      "Evaluating using CEM with lambda = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating CEM counterfactuals:   0%|          | 0/122 [00:00<?, ?it/s]No PN found!\n",
      "Generating CEM counterfactuals:   2%|▏         | 3/122 [00:14<09:18,  4.70s/it]No PN found!\n",
      "Generating CEM counterfactuals:  15%|█▍        | 18/122 [01:24<08:06,  4.68s/it]No PN found!\n",
      "Generating CEM counterfactuals:  19%|█▉        | 23/122 [01:46<07:34,  4.59s/it]No PN found!\n",
      "Generating CEM counterfactuals:  20%|██        | 25/122 [01:56<07:23,  4.58s/it]No PN found!\n",
      "Generating CEM counterfactuals:  21%|██▏       | 26/122 [02:00<07:23,  4.62s/it]No PN found!\n",
      "Generating CEM counterfactuals:  25%|██▌       | 31/122 [02:23<07:02,  4.64s/it]No PN found!\n",
      "Generating CEM counterfactuals:  27%|██▋       | 33/122 [02:33<06:54,  4.66s/it]No PN found!\n",
      "Generating CEM counterfactuals:  31%|███       | 38/122 [02:56<06:22,  4.55s/it]No PN found!\n",
      "Generating CEM counterfactuals:  36%|███▌      | 44/122 [03:24<06:03,  4.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[57], line 31\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(commun_negatives)), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating CEM counterfactuals\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     30\u001B[0m     x \u001B[38;5;241m=\u001B[39m commun_negatives[i:i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# keep shape (1, n_features)\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m     explanation \u001B[38;5;241m=\u001B[39m \u001B[43mcem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;66;03m# Extract original and PN (pertinent negative) instance\u001B[39;00m\n\u001B[0;32m     34\u001B[0m     original \u001B[38;5;241m=\u001B[39m explanation\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\alibi\\explainers\\cem.py:695\u001B[0m, in \u001B[0;36mCEM.explain\u001B[1;34m(self, X, Y, verbose)\u001B[0m\n\u001B[0;32m    693\u001B[0m \u001B[38;5;66;03m# find best PP or PN\u001B[39;00m\n\u001B[0;32m    694\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_attack \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 695\u001B[0m best_attack, grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[38;5;66;03m# output explanation dictionary\u001B[39;00m\n\u001B[0;32m    698\u001B[0m data \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(DEFAULT_DATA_CEM)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\alibi\\explainers\\cem.py:562\u001B[0m, in \u001B[0;36mCEM.attack\u001B[1;34m(self, X, Y, verbose)\u001B[0m\n\u001B[0;32m    559\u001B[0m         X_der_batch, X_der_batch_s \u001B[38;5;241m=\u001B[39m [], []\n\u001B[0;32m    561\u001B[0m \u001B[38;5;66;03m# compute and clip gradients defined in graph\u001B[39;00m\n\u001B[1;32m--> 562\u001B[0m grads_vars_graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_grads\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    563\u001B[0m grads_graph \u001B[38;5;241m=\u001B[39m [g \u001B[38;5;28;01mfor\u001B[39;00m g, _ \u001B[38;5;129;01min\u001B[39;00m grads_vars_graph][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    564\u001B[0m grads_graph \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(grads_graph, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclip[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclip[\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001B[0m, in \u001B[0;36mBaseSession.run\u001B[1;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m    965\u001B[0m run_metadata_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBuffer() \u001B[38;5;28;01mif\u001B[39;00m run_metadata \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    967\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 968\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions_ptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrun_metadata_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    970\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m run_metadata:\n\u001B[0;32m    971\u001B[0m     proto_data \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001B[0m, in \u001B[0;36mBaseSession._run\u001B[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001B[39;00m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001B[39;00m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m final_fetches \u001B[38;5;129;01mor\u001B[39;00m final_targets \u001B[38;5;129;01mor\u001B[39;00m (handle \u001B[38;5;129;01mand\u001B[39;00m feed_dict_tensor):\n\u001B[1;32m-> 1191\u001B[0m   results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_fetches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1192\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfeed_dict_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1193\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1194\u001B[0m   results \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001B[0m, in \u001B[0;36mBaseSession._do_run\u001B[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1368\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1371\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_run_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeeds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1372\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001B[0m, in \u001B[0;36mBaseSession._do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1376\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_do_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m   1377\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1379\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOpError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1380\u001B[0m     message \u001B[38;5;241m=\u001B[39m compat\u001B[38;5;241m.\u001B[39mas_text(e\u001B[38;5;241m.\u001B[39mmessage)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001B[0m, in \u001B[0;36mBaseSession._do_run.<locals>._run_fn\u001B[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_fn\u001B[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001B[0;32m   1359\u001B[0m   \u001B[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extend_graph()\n\u001B[1;32m-> 1361\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_tf_sessionrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cem_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001B[0m, in \u001B[0;36mBaseSession._call_tf_sessionrun\u001B[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[0;32m   1452\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_call_tf_sessionrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, options, feed_dict, fetch_list, target_list,\n\u001B[0;32m   1453\u001B[0m                         run_metadata):\n\u001B[1;32m-> 1454\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionRun_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1455\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1456\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(cost_of_recourses_l1,patch_artist=True, tick_labels=lambdas)\n",
    "plt.title(\"Cost of Recourse Across Models (L1 Distance)\")\n",
    "plt.xlabel(\"Lambda / Model Index\")\n",
    "plt.ylabel(\"L1 Distance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(cost_of_recourses_l2,patch_artist=True, tick_labels=lambdas)\n",
    "plt.title(\"Cost of Recourse Across Models (L2 Distance)\")\n",
    "plt.xlabel(\"Lambda / Model Index\")\n",
    "plt.ylabel(\"L2 Distance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "51b425e874202be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "l1_means = [np.mean(sublist) for sublist in cost_of_recourses_l1]\n",
    "## Plotting of the mean of Recourse genereated by dice After the Training with different Lambdas\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(lambdas, l1_means, marker='o', color='red')\n",
    "plt.title(\"Mean Recourse calculated by DiCE vs Lambda\")\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Mean Recourse \")\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "l2_means = [np.mean(sublist) for sublist in cost_of_recourses_l2]\n",
    "## Plotting of the mean of Recourse genereated by dice After the Training with different Lambdas\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(lambdas, l2_means, marker='o', color='red')\n",
    "plt.title(\"Mean Recourse calculated by DiCE vs Lambda\")\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Mean Recourse \")\n",
    "plt.grid(True)\n"
   ],
   "id": "16bc29d0c32801f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
